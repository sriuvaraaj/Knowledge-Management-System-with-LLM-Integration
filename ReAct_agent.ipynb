{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "import warnings\n",
    "from ragatouille import RAGPretrainedModel\n",
    "from langchain.tools import tool\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the GPT-4 model with Azure configuration \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpt_4 = AzureChatOpenAI(\n",
    "    azure_deployment= \"MagicPlatform-GPT4-O-GS-Test\",\n",
    "    api_version= \"2023-12-01-preview\",\n",
    "    temperature= 0.1,\n",
    "    model=\"gpt-4o\",\n",
    "    azure_endpoint=\"https://magicplatform-gpt4-o-gs-test-canadaeast.openai.azure.com/\",\n",
    "    api_key=\"***************\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration dictionary for OpenAI embeddings model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "OPENAI_MODEL_ARGS = {\n",
    "\"azure_deployment\": \"MagicPlatform-TextEmbedding-ADA-Test\",\n",
    "\"api_version\": \"2024-03-01-preview\",\n",
    "\"model\": \"text-embedding-ada-002\",\n",
    "\"azure_endpoint\": \"https://magicplatform-textembedding-ada-test-australiaeast.openai.azure.com/\",\n",
    "\"api_key\": \"***************\"\n",
    "}\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(**OPENAI_MODEL_ARGS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to load text documents from a specified directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents():\n",
    "    \n",
    "    loader = DirectoryLoader('data1/', glob='*.txt', loader_cls=TextLoader)\n",
    "    docs = loader.load()\n",
    "    print(f\"Loaded {len(docs)} documents.\")\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to split documents into chunks for better processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(docs, embedding_model):\n",
    "    text_splitter = SemanticChunker(embedding_model)\n",
    "    docs = text_splitter.create_documents([doc.page_content for doc in docs])\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to create a Chroma database from document chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db(docs, embedding_model):\n",
    "    db_chroma = Chroma.from_documents(docs, embedding_model)\n",
    "    return db_chroma\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to create a retriever using Cohere's reranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohere_ranker(db_chroma):\n",
    "    reranker = CohereRerank(cohere_api_key=\"***************\", model=\"rerank-english-v3.0\")\n",
    "    retriver = VectorStoreRetriever(vectorstore=db_chroma, reranker=reranker)\n",
    "    \n",
    "    return retriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load documents, split them into chunks, and create a Chroma database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 documents.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a1c19cf6-4773-4213-b635-19cc14023839',\n",
       " '239ee455-bf18-4100-bf99-4e0a39d885f6',\n",
       " 'e2a8ccaf-1499-41f9-9e79-d664942a31be',\n",
       " '5d6b68cd-12b6-44c1-94ce-23d29005ed3d',\n",
       " '299659e6-854e-4250-9125-47d6a552e40c',\n",
       " '48d94824-1455-47e9-8999-5615cca7fe98',\n",
       " '3b511e2b-51de-4a5c-9639-b01e1520e2f0',\n",
       " '25692cb6-de7b-4bc5-80af-fd1ff8adb96f',\n",
       " 'ab3b5e83-948e-41bc-a997-9f8bdd5a135c',\n",
       " '92067f4c-5da6-4d2b-a789-14ac4759b1a1',\n",
       " 'c80792a8-e9d1-459e-b34c-554a7776f9ef',\n",
       " 'b258f9a5-8cc3-46af-aa5f-6600dfe51b0a',\n",
       " 'c2b62c5c-d074-4793-8e7a-adb120fa3e43',\n",
       " '4e3b66af-c24b-49ae-b89e-221d4b2e2bf5',\n",
       " '8d5a5619-f73c-4dde-a7d9-897dd7666700',\n",
       " '85737638-683f-430d-9125-220602a21824']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = load_documents()\n",
    "chunks = split_into_chunks(docs, embedding_model)\n",
    "db_chroma = db(chunks, embedding_model)\n",
    "db_chroma.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool for classifying the content of a given file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def classify(file_name):\n",
    "\n",
    "    \"\"\"\n",
    "    Classify the content of a file as either an email or an invoice.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The name of the file to classify.\n",
    "\n",
    "    Returns:\n",
    "        str: Classification result (\"email\" or \"invoice\").\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"extract the file named with \" + file_name\n",
    "    retriever = cohere_ranker(db_chroma)\n",
    "    retrieved_docs = retriever.invoke(prompt)\n",
    "    \n",
    "    top_doc = retrieved_docs[0]\n",
    "    \n",
    "\n",
    "    gpt_prompt = (\n",
    "        prompt + top_doc.page_content + \n",
    "        \" classify the above content is from an invoice (email can contain the following: date, from, to, general greetings, general mail body) \"\n",
    "        \"or invoice (invoice can contain the following: total, amount, amt, tax, item names, and general invoice information). \"\n",
    "        \"give answer in one word (email or invoice)\"\n",
    "    )\n",
    "\n",
    "    response = gpt_4.invoke(gpt_prompt)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the RAG pretrained model for document compression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG = RAGPretrainedModel.from_pretrained('colbert-ir/colbertv2.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to create a contextual retriever based on ColBERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colbert_retriever(db):\n",
    "    base_retriever = db.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\":3}\n",
    "    )\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=RAG.as_langchain_document_compressor(k=3),\n",
    "        base_retriever=base_retriever\n",
    "    )\n",
    "    return compression_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool for extracting specific entities from a classified document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def extract_ent(file_name, entity_query):\n",
    "    \"\"\"\n",
    "    Extract entities from the specified email file based on the entity query.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The name of the email file.\n",
    "        entity_query (str): The query specifying which entities to extract.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with required entities.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    retriever = get_colbert_retriever(db_chroma)\n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=gpt_4,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    \n",
    "    enhanced_query = f\"Extract the following entities: {entity_query} from the document: {file_name}. Provide a clear and structured output.\"\n",
    "\n",
    "    \n",
    "    result = qa_chain({'query':enhanced_query})\n",
    "    return result['result']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize a conversational agent with specified tools and model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "\n",
    "\n",
    "agent_prompt = \"given the file_name and entity_query, use classify tool to classify if the file is email or invoice. if the file is invoice use extract_ent tool to get entities asked in entity_query\"\n",
    "\n",
    "\n",
    "tools = [classify, extract_ent]\n",
    "\n",
    "conversational_agent = initialize_agent(\n",
    "    agent='structured-chat-zero-shot-react-description',\n",
    "    tools=tools,\n",
    "    llm=gpt_4,\n",
    "    verbose=True,\n",
    "    max_iterations=4,\n",
    "    early_stopping_method='generate',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the agent with a specific file name and query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"classify\",\n",
      "  \"action_input\": {\n",
      "    \"file_name\": \"Myntra_invoice.txt\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mInvoice\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"extract_ent\",\n",
      "  \"action_input\": {\n",
      "    \"file_name\": \"Myntra_invoice.txt\",\n",
      "    \"entity_query\": \"Invoice Details\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mSure, here are the extracted invoice details from the document Myntra_invoice.txt:\n",
      "\n",
      "**Invoice Details:**\n",
      "\n",
      "- **Invoice Number:** MNT-987654\n",
      "- **Date:** 2024-11-01\n",
      "- **Customer:** Alice Johnson\n",
      "- **Address:** 456 Style Ave, Fashion City\n",
      "\n",
      "**Items:**\n",
      "\n",
      "1. **Item:** T-Shirt\n",
      "   - **Quantity:** 2\n",
      "   - **Unit Price:** $20.00\n",
      "   - **Total:** $40.00\n",
      "\n",
      "2. **Item:** Jeans\n",
      "   - **Quantity:** 1\n",
      "   - **Unit Price:** $60.00\n",
      "   - **Total:** $60.00\n",
      "\n",
      "3. **Item:** Sneakers\n",
      "   - **Quantity:** 1\n",
      "   - **Unit Price:** $80.00\n",
      "   - **Total:** $80.00\n",
      "\n",
      "**Total Amount:** $180.00\n",
      "\n",
      "**Notes:** Thank you for shopping at Myntra! Returns are accepted within 15 days.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Sure, here are the extracted invoice details from the document Myntra_invoice.txt:\\n\\n**Invoice Details:**\\n\\n- **Invoice Number:** MNT-987654\\n- **Date:** 2024-11-01\\n- **Customer:** Alice Johnson\\n- **Address:** 456 Style Ave, Fashion City\\n\\n**Items:**\\n\\n1. **Item:** T-Shirt\\n   - **Quantity:** 2\\n   - **Unit Price:** $20.00\\n   - **Total:** $40.00\\n\\n2. **Item:** Jeans\\n   - **Quantity:** 1\\n   - **Unit Price:** $60.00\\n   - **Total:** $60.00\\n\\n3. **Item:** Sneakers\\n   - **Quantity:** 1\\n   - **Unit Price:** $80.00\\n   - **Total:** $80.00\\n\\n**Total Amount:** $180.00\\n\\n**Notes:** Thank you for shopping at Myntra! Returns are accepted within 15 days.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'file name is Myntra_invoice.txt classify it and if the file is invoice then extract the required entity. Give Invoice Details',\n",
       " 'output': 'Sure, here are the extracted invoice details from the document Myntra_invoice.txt:\\n\\n**Invoice Details:**\\n\\n- **Invoice Number:** MNT-987654\\n- **Date:** 2024-11-01\\n- **Customer:** Alice Johnson\\n- **Address:** 456 Style Ave, Fashion City\\n\\n**Items:**\\n\\n1. **Item:** T-Shirt\\n   - **Quantity:** 2\\n   - **Unit Price:** $20.00\\n   - **Total:** $40.00\\n\\n2. **Item:** Jeans\\n   - **Quantity:** 1\\n   - **Unit Price:** $60.00\\n   - **Total:** $60.00\\n\\n3. **Item:** Sneakers\\n   - **Quantity:** 1\\n   - **Unit Price:** $80.00\\n   - **Total:** $80.00\\n\\n**Total Amount:** $180.00\\n\\n**Notes:** Thank you for shopping at Myntra! Returns are accepted within 15 days.'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent(\"file name is Myntra_invoice.txt classify it and if the file is invoice then extract the required entity. Give Invoice Details\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
